<!DOCTYPE html><html lang="en" class="scroll-smooth"><head><meta charSet="utf-8"/><script>!function(){try {var d=document.documentElement.classList;d.remove('light','dark');var e=localStorage.getItem('theme');if("system"===e||(!e&&true)){var t="(prefers-color-scheme: dark)",m=window.matchMedia(t);m.media!==t||m.matches?d.add('dark'):d.add('light')}else if(e) d.add(e)}catch(e){}}()</script><meta content="width=device-width, initial-scale=1" name="viewport"/><title>Posing Heads with Stable Diffusion</title><meta name="robots" content="follow, index"/><meta name="description"/><meta property="og:url" content="https://tailwind-nextjs-starter-blog.vercel.app/blog/posing-heads-with-stable-diffusion"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Stormin&#x27; the Castle "/><meta property="og:description"/><meta property="og:title" content="Posing Heads with Stable Diffusion"/><meta property="og:image" content="https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="https://twitter.com/johnrobinsn"/><meta name="twitter:title" content="Posing Heads with Stable Diffusion"/><meta name="twitter:description"/><meta name="twitter:image" content="https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"/><link rel="canonical" href="https://tailwind-nextjs-starter-blog.vercel.app/blog/new-features-in-v1/"/><meta property="article:published_time" content="2023-01-29T15:32:14.000Z"/><meta property="article:modified_time" content="2023-01-29T00:00:00.000Z"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tailwind-nextjs-starter-blog.vercel.app/blog/posing-heads-with-stable-diffusion"
  },
  "headline": "Posing Heads with Stable Diffusion",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://tailwind-nextjs-starter-blog.vercel.app/static/images/twitter-card.png"
    }
  ],
  "datePublished": "2023-01-29T15:32:14.000Z",
  "dateModified": "2023-01-29T00:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "John Robinson"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "John Robinson",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tailwind-nextjs-starter-blog.vercel.app/static/images/logo.png"
    }
  }
}</script><meta name="next-head-count" content="21"/><link rel="apple-touch-icon" sizes="76x76" href="/static/favicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><link rel="mask-icon" href="/static/favicons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#000000"/><meta name="theme-color" media="(prefers-color-scheme: light)" content="#fff"/><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#000"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preload" href="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/css/5f7aae2ba929017a.css" as="style"/><link rel="stylesheet" href="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/css/5f7aae2ba929017a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/webpack-46b41b6511f2a85e.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/main-ef8da00141a57265.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/pages/_app-3c9260fd20c809d8.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/675-415f2ef004e9374e.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/410-35c4fb535edd9439.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/712-1460c880a709bdc7.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/chunks/pages/blog/%5B...slug%5D-8ab66ff6ebabec4c.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/Hq9YW1FDIjnEcr4iKqFoB/_buildManifest.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/Hq9YW1FDIjnEcr4iKqFoB/_ssgManifest.js" defer=""></script><script src="https://pinkdragon1000.github.io/StorminTheCastle2/_next/static/Hq9YW1FDIjnEcr4iKqFoB/_middlewareManifest.js" defer=""></script></head><body class="bg-white text-black antialiased dark:bg-gray-900 dark:text-white"><div id="__next" data-reactroot=""><div class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex h-screen flex-col justify-between"><header class="flex items-center justify-between py-10"><div><a aria-label="Stormin&#x27; the Castle" href="/StorminTheCastle2"><div class="flex items-center justify-between"><div class="mr-3"><svg width="71" height="53" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M23.995 12.288h23.203c.317 0 .608-.127.752-.329.143-.2.114-.442-.077-.623L36.275.242C36.115.09 35.865 0 35.598 0c-.267 0-.52.09-.677.242l-11.6 11.094c-.191.181-.22.422-.078.623.144.202.436.329.752.329Z" fill="url(#logo_svg__a)"></path><path d="M70.979 20c0-.475-.545-.86-1.216-.86h-2.337c-.665 0-1.207.379-1.215.85l-.034 1.852h-2.859v-1.84c0-.476-.544-.862-1.215-.862H59.73c-.671 0-1.215.386-1.215.861v1.84H55.66v-1.84c0-.475-.544-.861-1.215-.861H52.07c-.671 0-1.215.385-1.216.86l-.011 7.889H45.24V14.622c0-.36-.41-.65-.917-.65H26.875c-.506 0-.917.29-.917.65V27.89h-5.555l.007-7.887c0-.229-.128-.448-.356-.61a1.507 1.507 0 0 0-.86-.252H16.77c-.671 0-1.216.386-1.216.861v1.84h-2.853v-1.84c0-.475-.545-.86-1.216-.86H9.113c-.671 0-1.216.385-1.216.86v1.84H5.04v-1.84c0-.475-.544-.86-1.216-.86H1.45c-.671 0-1.215.384-1.216.86L.188 53h26.306v-5.563c0-3.56 4.075-6.445 9.099-6.445s9.098 2.885 9.098 6.445V53h26.307l-.02-33ZM13.517 34.289c0 .36-.41.65-.918.65H8.001c-.507 0-.917-.29-.917-.65v-6.492c0-1.259 1.439-2.279 3.216-2.279 1.775 0 3.217 1.02 3.217 2.279v6.492Zm25.298-8.93c0 .36-.411.651-.918.651H33.3c-.507 0-.917-.29-.917-.65v-6.493c0-1.258 1.438-2.279 3.216-2.279 1.775 0 3.217 1.02 3.217 2.279v6.492Zm25.322 8.93c0 .36-.41.65-.917.65H58.62c-.507 0-.917-.29-.917-.65v-6.492c0-1.259 1.439-2.279 3.216-2.279 1.776 0 3.217 1.02 3.217 2.279v6.492Z" fill="url(#logo_svg__b)"></path><defs><linearGradient id="logo_svg__a" x1="43.907" y1="0.839" x2="31.62" y2="20.648" gradientUnits="userSpaceOnUse"><stop stop-color="#85E2F4"></stop><stop offset="1" stop-color="#56B7D2"></stop></linearGradient><linearGradient id="logo_svg__b" x1="59.237" y1="16.637" x2="18.461" y2="75.528" gradientUnits="userSpaceOnUse"><stop stop-color="#85E2F4"></stop><stop offset="1" stop-color="#56B7D2"></stop></linearGradient></defs></svg></div><div class="hidden h-6 text-2xl font-semibold sm:block md:text-4xl">Stormin&#x27; the Castle</div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/StorminTheCastle2/tags">Tags</a><a class="p-1 font-medium text-gray-900 dark:text-gray-100 sm:p-4" href="/StorminTheCastle2/about">About</a></div><button aria-label="Toggle Dark Mode" type="button" class="ml-1 mr-1 h-8 w-8 rounded p-1 sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button type="button" class="ml-1 mr-1 h-8 w-8 rounded py-1" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed top-0 left-0 z-10 h-full w-full transform bg-gray-200 opacity-95 duration-300 ease-in-out dark:bg-gray-800 translate-x-full"><div class="flex justify-end"><button type="button" class="mr-5 mt-11 h-8 w-8 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><nav class="fixed mt-8 h-full"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/StorminTheCastle2/tags">Tags</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/StorminTheCastle2/about">About</a></div></nav></div></div></div></header><main class="mb-auto"><div class="mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0"><div class="fixed right-8 bottom-8 hidden flex-col gap-3 md:hidden"><button aria-label="Scroll To Comment" type="button" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M18 10c0 3.866-3.582 7-8 7a8.841 8.841 0 01-4.083-.98L2 17l1.338-3.123C2.493 12.767 2 11.434 2 10c0-3.866 3.582-7 8-7s8 3.134 8 7zM7 9H5v2h2V9zm8 0h-2v2h2V9zM9 9h2v2H9V9z" clip-rule="evenodd"></path></svg></button><button aria-label="Scroll To Top" type="button" class="rounded-full bg-gray-200 p-2 text-gray-500 transition-all hover:bg-gray-300 dark:bg-gray-700 dark:text-gray-400 dark:hover:bg-gray-600"><svg class="h-5 w-5" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M3.293 9.707a1 1 0 010-1.414l6-6a1 1 0 011.414 0l6 6a1 1 0 01-1.414 1.414L11 5.414V17a1 1 0 11-2 0V5.414L4.707 9.707a1 1 0 01-1.414 0z" clip-rule="evenodd"></path></svg></button></div><article><div class="xl:divide-y xl:divide-gray-200 xl:dark:divide-gray-700"><header class="pt-6 xl:pb-6"><div class="space-y-1 text-center"><dl class="space-y-10"><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2023-01-29T15:32:14.000Z">Sunday, January 29, 2023</time></dd></div></dl><div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Posing Heads with Stable Diffusion</h1></div></div></header><div class="divide-y divide-gray-200 pb-8 dark:divide-gray-700 xl:grid xl:grid-cols-4 xl:gap-x-6 xl:divide-y-0" style="grid-template-rows:auto 1fr"><dl class="pt-6 pb-10 xl:border-b xl:border-gray-200 xl:pt-11 xl:dark:border-gray-700"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center space-x-8 sm:space-x-12 xl:block xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2738%27%20height=%2738%27/%3e"/></span><img alt="avatar" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="h-10 w-10 rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="avatar" srcSet="static/images/avatar.jpeg?imwidth=48 1x, static/images/avatar.jpeg?imwidth=96 2x" src="static/images/avatar.jpeg?imwidth=96" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="h-10 w-10 rounded-full" loading="lazy"/></noscript></span><dl class="whitespace-nowrap text-sm font-medium leading-5"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-gray-100">John Robinson</dd><dt class="sr-only">Twitter</dt><dd><a target="_blank" rel="noopener noreferrer" href="https://twitter.com/johnrobinsn" class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400">@johnrobinsn</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:col-span-3 xl:row-span-2 xl:pb-0"><div class="prose max-w-none pt-10 pb-8 dark:prose-dark"><p>This is a quick overview of my experiments using an Image Regression Model to guide head position, pose and scale of &quot;headshot&quot;-style images generated by Stable Diffusion.</p><p><strong>All with no fine-tuning of the Stable Diffusion model!</strong></p><p>In these experiments, I have not done any fine-tuning of the Stable Diffusion model. Rather I&#x27;m using my own image regression model (trained on a head pose dataset) to guide Stable Diffusion&#x27;s image generation at inference time, operating in latent space rather than image space.</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27832%27%20height=%27182%27/%3e"/></span><img alt="photo of a woman" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="photo of a woman" srcSet="static/images/posingHeads/sample1.jpeg?imwidth=1080 1x, static/images/posingHeads/sample1.jpeg?imwidth=1920 2x" src="static/images/posingHeads/sample1.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>Prompt: &#x27;Photo of a woman&#x27;</p><p>This is built on top of a technique outlined in <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/johnowhitaker">Jonathon Whitaker&#x27;s</a> ground-breaking article, <a target="_blank" rel="noopener noreferrer" href="https://wandb.ai/johnowhitaker/midu-guidance/reports/Mid-U-Guidance-Fast-Classifier-Guidance-for-Latent-Diffusion-Models--VmlldzozMjg0NzA1">Mid-U Guidance: Fast Classifier Guidance for Latent Diffusion Models</a>. In this article, He describes a <strong>new technique</strong> for efficiently using an image classifier model to guide Stable Diffusion inference.</p><p>Latent diffusion models such as Stable Diffusion make it difficult to use image models for classifier guidance, since they operate internally on a highly compressed image represention (latents). Trying to use a classifier that operates in image space to steer the image generation process, would require tracing gradients not only through the classifier model, but also back through the decoder for the VAE and the upsampling path of Stable Diffusion&#x27;s UNet making it very memory and compute intensive.</p><p>The magic of JohnO&#x27;s approach is his realization that the Stable Diffusion encoder is a very powerful feature extractor and if there was a way to intercept the feature map from the encoder that this could be used as the backbone of a classifier model that operates in latent space rather than image space.</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27736%27%20height=%27396%27/%3e"/></span><img alt="midu" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="midu" srcSet="static/images/posingHeads/midu.jpeg?imwidth=750 1x, static/images/posingHeads/midu.jpeg?imwidth=1920 2x" src="static/images/posingHeads/midu.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>This diagram[1] above illustrates the UNet from Stable Diffusion. The blocks with the blue background show the &quot;encoder&quot; (downsampling network) and the orange blocks show the decoder (upsampling network). The block in the middle is called the mid-block and is the point at which the encoder and decoder meet.</p><p>JohnO descibes using a PyTorch hook to intercept the feature map from the mid-block of Stable Diffusions UNet giving us a (1280,8,8) compact but rich feature map upon which to train our custom model.</p><p>For my experiments, I built an image regression model that I&#x27;ve trained to predict head position, orientation and scale from input images.</p><p>Later I&#x27;m able to use this model at Stable Diffusion inference time to specify numeric targets for head position, orientation and scale.</p><h3 id="sample-images"><a href="#sample-images" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Sample Images</h3><p>In these sample images, I’m using my model to steer Stable Diffusion to center the generated headshot and to “pose” the generated image in a given direction not with a text prompt, but by using my model to steer the orientation using numeric targets for pitch, yaw, x, y and scale.</p><p>Interpolation in pitch and yaw space with specified centered head position, I can generate a wide variety of head poses.</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%271500%27%20height=%271500%27/%3e"/></span><img alt="grid" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="grid" srcSet="static/images/posingHeads/grid2.jpeg?imwidth=1920 1x, static/images/posingHeads/grid2.jpeg?imwidth=3840 2x" src="static/images/posingHeads/grid2.jpeg?imwidth=3840" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>For demonstration purposes, I&#x27;m mapping these numeric pose targets to one of &#x27;left&#x27;, &#x27;right&#x27;, &#x27;up&#x27;, &#x27;down&#x27;, and &#x27;front&#x27;.</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27832%27%20height=%27182%27/%3e"/></span><img alt="sample2" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="sample2" srcSet="static/images/posingHeads/sample2.jpeg?imwidth=1080 1x, static/images/posingHeads/sample2.jpeg?imwidth=1920 2x" src="static/images/posingHeads/sample2.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>Prompt: &#x27;Photo of a woman&#x27;</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27832%27%20height=%27182%27/%3e"/></span><img alt="sample3" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="sample3" srcSet="static/images/posingHeads/sample3.jpeg?imwidth=1080 1x, static/images/posingHeads/sample3.jpeg?imwidth=1920 2x" src="static/images/posingHeads/sample3.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>Prompt: “magazine with a woman on the cover”</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27832%27%20height=%27182%27/%3e"/></span><img alt="sample4" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="sample4" srcSet="static/images/posingHeads/sample4.jpeg?imwidth=1080 1x, static/images/posingHeads/sample4.jpeg?imwidth=1920 2x" src="static/images/posingHeads/sample4.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>Prompt: “photo of a man”</p><div><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27832%27%20height=%27182%27/%3e"/></span><img alt="sample5" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="sample5" srcSet="static/images/posingHeads/sample5.jpeg?imwidth=1080 1x, static/images/posingHeads/sample5.jpeg?imwidth=1920 2x" src="static/images/posingHeads/sample5.jpeg?imwidth=1920" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><p>Prompt: “photo of a man”</p><h3 id="afterword"><a href="#afterword" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Afterword</h3><p>This is a very rich space to explore and I have a ton of other related research ideas. I used miniai, a new &quot;experimental&quot; machine larning framework from <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/jeremyphoward">@jeremyphoward</a> to train the model that I described in this article. It&#x27;s super flexible and its modest size make it a great platform for experimentation.</p><h4 id="references"><a href="#references" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>References</h4><p>[1] <a target="_blank" rel="noopener noreferrer" href="https://wandb.ai/johnowhitaker/midu-guidance/reports/Mid-U-Guidance-Fast-Classifier-Guidance-for-Latent-Diffusion-Models--VmlldzozMjg0NzA1">Mid-U Guidance: Fast Classifier Guidance for Latent Diffusion Models</a> by Jonathon Whitaker 2023</p><p>For all commercial inquiries, please contact <a target="_blank" rel="noopener noreferrer" href="mailto:sales@liquidthought.com">sales@liquidthought.com</a></p></div><div class="pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300"><a target="_blank" rel="nofollow" href="https://mobile.twitter.com/search?q=https%3A%2F%2Ftailwind-nextjs-starter-blog.vercel.app%2Fblog%2Fposing-heads-with-stable-diffusion">Discuss on Twitter</a> • <a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog/blob/master/data/blog/posing-heads-with-stable-diffusion.md">View on GitHub</a></div><div id="comment"></div></div><footer><div class="divide-gray-200 text-sm font-medium leading-5 dark:divide-gray-700 xl:col-start-1 xl:row-start-2 xl:divide-y"><div class="py-4 xl:py-8"><h2 class="text-xs uppercase tracking-wide text-gray-500 dark:text-gray-400">Tags</h2><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/StorminTheCastle2/tags/diffusion">Diffusion</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/StorminTheCastle2/tags/mid-u">MID-U</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/StorminTheCastle2/tags/miniai">miniai</a></div></div><div class="flex justify-between py-4 xl:block xl:space-y-8 xl:py-8"><div><h2 class="text-xs uppercase tracking-wide text-gray-500 dark:text-gray-400">Previous Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/StorminTheCastle2/blog/01_classification">Object Detection from Scratch - Part 1</a></div></div></div></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/StorminTheCastle2/blog">← Back to the blog</a></div></footer></div></div></article></div></main><footer><div class="mt-16 flex flex-col items-center"><div class="mb-3 flex space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:johnrobinsn@gmail.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/johnrobinsn"><span class="sr-only">github</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/johnrobinsonsprofile/"><span class="sr-only">linkedin</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://twitter.com/johnrobinsn"><span class="sr-only">twitter</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" class="fill-current text-gray-700 hover:text-blue-500 dark:text-gray-200 dark:hover:text-blue-400 h-6 w-6"><path d="M23.953 4.57a10 10 0 0 1-2.825.775 4.958 4.958 0 0 0 2.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 0 0-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 0 0-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 0 1-2.228-.616v.06a4.923 4.923 0 0 0 3.946 4.827 4.996 4.996 0 0 1-2.212.085 4.936 4.936 0 0 0 4.604 3.417 9.867 9.867 0 0 1-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 0 0 7.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0 0 24 4.59z"></path></svg></a></div><div class="mb-2 flex space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>John Robinson</div><div> • </div><div>© 2023</div><div> • </div><a href="/StorminTheCastle2">Stormin&#x27; the Castle </a></div><div class="mb-8 text-sm text-gray-500 dark:text-gray-400"><a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a></div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"mdxSource":"var Component=(()=\u003e{var l=Object.create;var r=Object.defineProperty;var c=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var p=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var s=t=\u003er(t,\"__esModule\",{value:!0});var g=(t,a)=\u003e()=\u003e(a||t((a={exports:{}}).exports,a),a.exports),u=(t,a)=\u003e{s(t);for(var n in a)r(t,n,{get:a[n],enumerable:!0})},w=(t,a,n)=\u003e{if(a\u0026\u0026typeof a==\"object\"||typeof a==\"function\")for(let i of m(a))!f.call(t,i)\u0026\u0026i!==\"default\"\u0026\u0026r(t,i,{get:()=\u003ea[i],enumerable:!(n=c(a,i))||n.enumerable});return t},b=t=\u003ew(s(r(t!=null?l(p(t)):{},\"default\",t\u0026\u0026t.__esModule\u0026\u0026\"default\"in t?{get:()=\u003et.default,enumerable:!0}:{value:t,enumerable:!0})),t);var h=g((D,d)=\u003e{d.exports=_jsx_runtime});var j={};u(j,{default:()=\u003ev,frontmatter:()=\u003ey});var e=b(h()),y={title:\"Posing Heads with Stable Diffusion\",date:new Date(1675006334e3),lastmod:\"2023-01-29\",tags:[\"Diffusion\",\"MID-U\",\"miniai\"],draft:!1,canonicalUrl:\"https://tailwind-nextjs-starter-blog.vercel.app/blog/new-features-in-v1/\"};function k(t={}){let{wrapper:a}=t.components||{};return a?(0,e.jsx)(a,Object.assign({},t,{children:(0,e.jsx)(n,{})})):n();function n(){let i=Object.assign({p:\"p\",strong:\"strong\",div:\"div\",a:\"a\",h3:\"h3\",span:\"span\",h4:\"h4\"},t.components),{Image:o}=i;return o||x(\"Image\",!0),(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(i.p,{children:'This is a quick overview of my experiments using an Image Regression Model to guide head position, pose and scale of \"headshot\"-style images generated by Stable Diffusion.'}),(0,e.jsx)(i.p,{children:(0,e.jsx)(i.strong,{children:\"All with no fine-tuning of the Stable Diffusion model!\"})}),(0,e.jsx)(i.p,{children:\"In these experiments, I have not done any fine-tuning of the Stable Diffusion model. Rather I'm using my own image regression model (trained on a head pose dataset) to guide Stable Diffusion's image generation at inference time, operating in latent space rather than image space.\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"photo of a woman\",src:\"/static/images/posingHeads/sample1.jpeg\",width:\"832\",height:\"182\"})}),(0,e.jsx)(i.p,{children:\"Prompt: 'Photo of a woman'\"}),(0,e.jsxs)(i.p,{children:[\"This is built on top of a technique outlined in \",(0,e.jsx)(i.a,{href:\"https://twitter.com/johnowhitaker\",children:\"Jonathon Whitaker's\"}),\" ground-breaking article, \",(0,e.jsx)(i.a,{href:\"https://wandb.ai/johnowhitaker/midu-guidance/reports/Mid-U-Guidance-Fast-Classifier-Guidance-for-Latent-Diffusion-Models--VmlldzozMjg0NzA1\",children:\"Mid-U Guidance: Fast Classifier Guidance for Latent Diffusion Models\"}),\". In this article, He describes a \",(0,e.jsx)(i.strong,{children:\"new technique\"}),\" for efficiently using an image classifier model to guide Stable Diffusion inference.\"]}),(0,e.jsx)(i.p,{children:\"Latent diffusion models such as Stable Diffusion make it difficult to use image models for classifier guidance, since they operate internally on a highly compressed image represention (latents). Trying to use a classifier that operates in image space to steer the image generation process, would require tracing gradients not only through the classifier model, but also back through the decoder for the VAE and the upsampling path of Stable Diffusion's UNet making it very memory and compute intensive.\"}),(0,e.jsx)(i.p,{children:\"The magic of JohnO's approach is his realization that the Stable Diffusion encoder is a very powerful feature extractor and if there was a way to intercept the feature map from the encoder that this could be used as the backbone of a classifier model that operates in latent space rather than image space.\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"midu\",src:\"/static/images/posingHeads/midu.jpeg\",width:\"736\",height:\"396\"})}),(0,e.jsx)(i.p,{children:'This diagram[1] above illustrates the UNet from Stable Diffusion. The blocks with the blue background show the \"encoder\" (downsampling network) and the orange blocks show the decoder (upsampling network). The block in the middle is called the mid-block and is the point at which the encoder and decoder meet.'}),(0,e.jsx)(i.p,{children:\"JohnO descibes using a PyTorch hook to intercept the feature map from the mid-block of Stable Diffusions UNet giving us a (1280,8,8) compact but rich feature map upon which to train our custom model.\"}),(0,e.jsx)(i.p,{children:\"For my experiments, I built an image regression model that I've trained to predict head position, orientation and scale from input images.\"}),(0,e.jsx)(i.p,{children:\"Later I'm able to use this model at Stable Diffusion inference time to specify numeric targets for head position, orientation and scale.\"}),(0,e.jsxs)(i.h3,{id:\"sample-images\",children:[(0,e.jsx)(i.a,{href:\"#sample-images\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(i.span,{className:\"icon icon-link\"})}),\"Sample Images\"]}),(0,e.jsx)(i.p,{children:\"In these sample images, I\\u2019m using my model to steer Stable Diffusion to center the generated headshot and to \\u201Cpose\\u201D the generated image in a given direction not with a text prompt, but by using my model to steer the orientation using numeric targets for pitch, yaw, x, y and scale.\"}),(0,e.jsx)(i.p,{children:\"Interpolation in pitch and yaw space with specified centered head position, I can generate a wide variety of head poses.\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"grid\",src:\"/static/images/posingHeads/grid2.jpeg\",width:\"1500\",height:\"1500\"})}),(0,e.jsx)(i.p,{children:\"For demonstration purposes, I'm mapping these numeric pose targets to one of 'left', 'right', 'up', 'down', and 'front'.\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"sample2\",src:\"/static/images/posingHeads/sample2.jpeg\",width:\"832\",height:\"182\"})}),(0,e.jsx)(i.p,{children:\"Prompt: 'Photo of a woman'\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"sample3\",src:\"/static/images/posingHeads/sample3.jpeg\",width:\"832\",height:\"182\"})}),(0,e.jsx)(i.p,{children:\"Prompt: \\u201Cmagazine with a woman on the cover\\u201D\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"sample4\",src:\"/static/images/posingHeads/sample4.jpeg\",width:\"832\",height:\"182\"})}),(0,e.jsx)(i.p,{children:\"Prompt: \\u201Cphoto of a man\\u201D\"}),(0,e.jsx)(i.div,{children:(0,e.jsx)(o,{alt:\"sample5\",src:\"/static/images/posingHeads/sample5.jpeg\",width:\"832\",height:\"182\"})}),(0,e.jsx)(i.p,{children:\"Prompt: \\u201Cphoto of a man\\u201D\"}),(0,e.jsxs)(i.h3,{id:\"afterword\",children:[(0,e.jsx)(i.a,{href:\"#afterword\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(i.span,{className:\"icon icon-link\"})}),\"Afterword\"]}),(0,e.jsxs)(i.p,{children:['This is a very rich space to explore and I have a ton of other related research ideas. I used miniai, a new \"experimental\" machine larning framework from ',(0,e.jsx)(i.a,{href:\"https://twitter.com/jeremyphoward\",children:\"@jeremyphoward\"}),\" to train the model that I described in this article. It's super flexible and its modest size make it a great platform for experimentation.\"]}),(0,e.jsxs)(i.h4,{id:\"references\",children:[(0,e.jsx)(i.a,{href:\"#references\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,e.jsx)(i.span,{className:\"icon icon-link\"})}),\"References\"]}),(0,e.jsxs)(i.p,{children:[\"[1] \",(0,e.jsx)(i.a,{href:\"https://wandb.ai/johnowhitaker/midu-guidance/reports/Mid-U-Guidance-Fast-Classifier-Guidance-for-Latent-Diffusion-Models--VmlldzozMjg0NzA1\",children:\"Mid-U Guidance: Fast Classifier Guidance for Latent Diffusion Models\"}),\" by Jonathon Whitaker 2023\"]}),(0,e.jsxs)(i.p,{children:[\"For all commercial inquiries, please contact \",(0,e.jsx)(i.a,{href:\"mailto:sales@liquidthought.com\",children:\"sales@liquidthought.com\"})]})]})}}var v=k;function x(t,a){throw new Error(\"Expected \"+(a?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\")}return j;})();\n;return Component;","toc":[{"value":"Sample Images","url":"#sample-images","depth":3},{"value":"Afterword","url":"#afterword","depth":3},{"value":"References","url":"#references","depth":4}],"frontMatter":{"readingTime":{"text":"4 min read","minutes":3.065,"time":183900,"words":613},"slug":"posing-heads-with-stable-diffusion","fileName":"posing-heads-with-stable-diffusion.md","title":"Posing Heads with Stable Diffusion","date":"2023-01-29T15:32:14.000Z","lastmod":"2023-01-29","tags":["Diffusion","MID-U","miniai"],"draft":false,"canonicalUrl":"https://tailwind-nextjs-starter-blog.vercel.app/blog/new-features-in-v1/"}},"authorDetails":[{"readingTime":{"text":"1 min read","minutes":0.18,"time":10800,"words":36},"slug":["default"],"fileName":"default.md","name":"John Robinson","avatar":"/static/images/avatar.jpeg","occupation":"Technologist AI/ML/Vision","email":"johnrobinsn@gmail.com","github":"https://github.com/johnrobinsn","twitter":"https://twitter.com/johnrobinsn","linkedin":"https://www.linkedin.com/in/johnrobinsonsprofile/","date":null}],"prev":{"title":"Object Detection from Scratch - Part 1","date":"2023-01-12T15:32:14.000Z","lastmod":"2023-01-29","tags":["object detection","code"],"draft":false,"slug":"01_classification"},"next":null},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["posing-heads-with-stable-diffusion"]},"buildId":"Hq9YW1FDIjnEcr4iKqFoB","assetPrefix":"https://pinkdragon1000.github.io/StorminTheCastle2","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>